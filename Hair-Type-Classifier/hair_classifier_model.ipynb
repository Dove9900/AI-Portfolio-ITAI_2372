{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Hair Type Classification \u2013 Clean Local Notebook\n\nHybrid version rebuilt from the original Colab notebook.\n\nThis notebook trains a convolutional neural network (MobileNetV2 backbone) to classify hair types\nfrom images stored in a local folder structure.\n\nExpected folder layout (relative to this notebook):\n\n```text\nHairdata/\n    Straight/\n    Wavy/\n    curly/\n    kinky/\n    dreadlocks/\n```\n\nEach subfolder should contain images for that class.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Imports and dataset configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Base directory where the dataset is stored (relative path)\n",
        "DATA_DIR = os.path.join(os.getcwd(), \"Hairdata\")\n",
        "\n",
        "print(\"Dataset directory:\", DATA_DIR)\n",
        "print(\"Classes available:\", os.listdir(DATA_DIR))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load images into TensorFlow datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "img_height = 224\n",
        "img_width = 224\n",
        "batch_size = 32\n",
        "seed = 42\n",
        "\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    DATA_DIR,\n",
        "    validation_split=0.2,  # 80% training, 20% validation\n",
        "    subset=\"training\",\n",
        "    seed=seed,\n",
        "    image_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        ")\n",
        "\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    DATA_DIR,\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        "    seed=seed,\n",
        "    image_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        ")\n",
        "\n",
        "class_names = train_ds.class_names\n",
        "num_classes = len(class_names)\n",
        "\n",
        "print(\"Detected classes:\", class_names)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Optional: diagnose problematic image files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "# Cache, shuffle and prefetch for performance\n",
        "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "print(\"Starting TensorFlow-based image diagnostic...\")\n",
        "problematic_files_tf = []\n",
        "\n",
        "def can_decode_tf(filepath):\n",
        "    \"\"\"Return True if TensorFlow can decode the image, False otherwise.\"\"\"\n",
        "    try:\n",
        "        img_bytes = tf.io.read_file(filepath)\n",
        "        tf.image.decode_image(img_bytes, channels=3, expand_animations=False)\n",
        "        return True\n",
        "    except (tf.errors.InvalidArgumentError, tf.errors.OpError) as e:\n",
        "        print(f\"TensorFlow decoding error for {filepath}: {e}\")\n",
        "        return False\n",
        "    except Exception as e:\n",
        "        print(f\"Unexpected error during TensorFlow decoding for {filepath}: {e}\")\n",
        "        return False\n",
        "\n",
        "for class_name in class_names:\n",
        "    class_path = os.path.join(DATA_DIR, class_name)\n",
        "    if os.path.isdir(class_path):\n",
        "        for filename in os.listdir(class_path):\n",
        "            file_path = os.path.join(class_path, filename)\n",
        "            if os.path.isfile(file_path) and not can_decode_tf(file_path):\n",
        "                problematic_files_tf.append(file_path)\n",
        "    else:\n",
        "        print(f\"Warning: directory not found: {class_path}\")\n",
        "\n",
        "if problematic_files_tf:\n",
        "    print(\"\\nProblematic files detected (TensorFlow could not decode these):\")\n",
        "    for p in problematic_files_tf:\n",
        "        print(\" -\", p)\n",
        "    print(\"\\nPlease remove or fix these files and re-run the dataset loading step.\")\n",
        "else:\n",
        "    print(\"\\nAll files appear to be valid images for TensorFlow.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualize a few training images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 8))\n",
        "for images, labels in train_ds.take(1):\n",
        "    for i in range(9):\n",
        "        ax = plt.subplot(3, 3, i + 1)\n",
        "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "        plt.title(class_names[labels[i]])\n",
        "        plt.axis(\"off\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Define the CNN model (MobileNetV2 backbone)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "data_augmentation = keras.Sequential(\n",
        "    [\n",
        "        layers.RandomFlip(\"horizontal\"),\n",
        "        layers.RandomRotation(0.05),\n",
        "        layers.RandomZoom(0.1),\n",
        "    ]\n",
        ")\n",
        "\n",
        "base_model = keras.applications.MobileNetV2(\n",
        "    input_shape=(img_height, img_width, 3),\n",
        "    include_top=False,\n",
        "    weights=\"imagenet\",\n",
        ")\n",
        "\n",
        "# Freeze backbone initially\n",
        "base_model.trainable = False\n",
        "\n",
        "inputs = keras.Input(shape=(img_height, img_width, 3))\n",
        "x = data_augmentation(inputs)\n",
        "x = keras.applications.mobilenet_v2.preprocess_input(x)\n",
        "x = base_model(x, training=False)\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "x = layers.Dropout(0.2)(x)\n",
        "outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "epochs = 10\n",
        "\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=epochs,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Detailed evaluation (classification report + confusion matrix)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "for images, labels in val_ds:\n",
        "    preds = model.predict(images, verbose=0)\n",
        "    y_true.extend(labels.numpy())\n",
        "    y_pred.extend(np.argmax(preds, axis=1))\n",
        "\n",
        "y_true = np.array(y_true)\n",
        "y_pred = np.array(y_pred)\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_true, y_pred, target_names=class_names))\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "print(\"Confusion Matrix:\\n\", cm)\n",
        "\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(\n",
        "    cm,\n",
        "    annot=True,\n",
        "    fmt=\"d\",\n",
        "    xticklabels=class_names,\n",
        "    yticklabels=class_names,\n",
        ")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.title(\"Confusion Matrix - Hair Type Classifier\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Save the trained model locally"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "MODEL_PATH = os.path.join(os.getcwd(), \"hair_type_model.keras\")\n",
        "model.save(MODEL_PATH)\n",
        "print(\"Model saved at:\", MODEL_PATH)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Predict hair type for a single image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "\n",
        "def predict_image(path):\n",
        "    img = Image.open(path).convert(\"RGB\")\n",
        "    img_resized = img.resize((img_width, img_height))\n",
        "    img_array = np.array(img_resized)\n",
        "    img_array = np.expand_dims(img_array, axis=0)  # shape (1, h, w, 3)\n",
        "\n",
        "    predictions = model.predict(img_array)\n",
        "    pred_idx = np.argmax(predictions[0])\n",
        "    pred_class = class_names[pred_idx]\n",
        "    confidence = float(predictions[0][pred_idx])\n",
        "\n",
        "    plt.imshow(img)\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(f\"Predicted: {pred_class} ({confidence:.4f})\")\n",
        "    plt.show()\n",
        "\n",
        "    return pred_class, confidence\n",
        "\n",
        "# Example usage (uncomment and set an image path):\n",
        "# predict_image(\"./example_hair.jpg\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. (Optional) Save additional information as pickle files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "PKL_DIR = os.path.join(os.getcwd(), \"pkl\")\n",
        "os.makedirs(PKL_DIR, exist_ok=True)\n",
        "print(\"PKL directory:\", PKL_DIR)\n",
        "\n",
        "# Save class names\n",
        "class_names_path = os.path.join(PKL_DIR, \"hair_class_names.pkl\")\n",
        "with open(class_names_path, \"wb\") as f:\n",
        "    pickle.dump(class_names, f)\n",
        "print(\"Saved:\", class_names_path)\n",
        "\n",
        "# Save classification report as dict for later analysis\n",
        "report_dict = classification_report(\n",
        "    y_true,\n",
        "    y_pred,\n",
        "    target_names=class_names,\n",
        "    output_dict=True,\n",
        ")\n",
        "\n",
        "report_path = os.path.join(PKL_DIR, \"classification_report.pkl\")\n",
        "with open(report_path, \"wb\") as f:\n",
        "    pickle.dump(report_dict, f)\n",
        "print(\"Saved:\", report_path)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}